# ðŸ§  RAG-Based Conversational System with LLaMA, FAISS, and Multilingual TTS Integration

## Overview
A complete Retrieval-Augmented Generation (RAG) pipeline designed for humanoid conversational systems, integrating sentence-level chunking, FAISS-based semantic retrieval, reranking, memory, multi-hop reasoning, web search fallback, and multilingual speech I/O.
---
## ðŸ”¹ Pipeline Overview
### 1. Document Chunking
- Converted raw documents into semantic chunks.
- Used sentence-based chunking (better context flow than character chunking).
- Split text using NLTK sentence splitter.
- Created chunks of 3 sentences, with 1-sentence overlap for continuity.

---

### 2. Embedding Generation and Vector Storage
- Downloaded and initialized a **sentence embedding model**.
- Converted each text chunk into an **embedding vector**.
- Stored embedding vectors in a **FAISS vector database** for fast similarity search.
- 
---

- The LLM handles query understanding, document synthesis, and final answer generation.

---

### 3. Retrieval and Cross-Encoder Reranking
- For every user query:
- Converted the query text into an **embedding vector**.
- Retrieved the **top 10 most similar chunks** from FAISS.
- Applied **cross-encoder reranking** to filter out irrelevant chunks:
  - Helps discard false positives where no chunk is meaningfully relevant.
- The top reranked contexts are provided to the LLM for response synthesis.

---

### 4. Conversational Memory
- Implemented **session-based memory** for contextual continuity.
- The system remembers past questions and answers within a session.
- Memory is stored in a local database for retrieval across turns.

---

### 5. Web Search Integration
- Integrated **DuckDuckGo Search API** for fallback retrieval.
- Triggered when no relevant chunk is found in FAISS or the confidence is low.
- Uses DuckDuckGoâ€™s free API (with rate limits) to fetch real-time web information.

---

### 6. Complex Query Decomposition
- Detected when queries are **complex or multi-part**.
- Decomposed them into **sub-questions**.
- Each sub-question is processed through the RAG pipeline individually.
- Aggregated and stored the sub-answers in memory for holistic reasoning and reuse.

---

### 7. Multilingual Voice Interaction (TTS + ASR)
- Integrated **speech-to-text (ASR)** and **text-to-speech (TTS)** for humanoid interaction.
- Process:
1. Converts **audio input â†’ text**.
2. **Detects input language** automatically.
3. **Translates** non-English text to English.
4. Feeds the translated question into the RAG system.
5. **Translates response back** to the original language.
6. Generates **audio output** so the user can hear the answer.

---

## âš™ï¸ Key Features
- Sentence-level semantic chunking with overlap.
- FAISS-based vector similarity retrieval.
- Cross-encoder reranking for precise answer selection.
- LLaMA 2 for reasoning and conversation.
- Contextual memory across sessions.
- Web fallback with DuckDuckGo Search.
- Support for multilingual queries and voice-based interaction.

---

## ðŸ§© Tech Stack
| Component | Library / Tool |
|------------|----------------|
| Text Splitting | `NLTK` |
| Embeddings | Sentence Transformers / Hugging Face model |
| Vector Store | `FAISS` |
| LLM | `LlamaCpp` (LLaMA 2 - 7B) |
| Memory | LangChain conversational memory |
| Web Search | DuckDuckGo Search API |
| Speech & Translation | Google Translate |

---
## ðŸ—ï¸ Architecture Diagram

The following flow illustrates the entire pipeline of the system:

```mermaid
flowchart TD
    A[Documents] --> B[Sentence based Chunking - NLTK]
    B --> C[Embedding Model]
    C --> D[(FAISS Vector DB)]
    
    subgraph Retrieval_Pipeline
        E1[User Query - Text or Voice] --> E2[ASR Language Detect Translate]
        E2 --> E3[Query Embedding]
        E3 --> E4[FAISS Top 10 Retrieval]
        E4 --> E5[Cross Encoder Reranker]
        E5 --> E6[Top k Relevant Chunks]
    end
    
    D --> E4
    E6 --> F[LLaMA LLM]
    F --> G1[Answer from RAG]
    F --> G2[Web Search - DuckDuckGo Fallback]
    G1 --> H[Translate Back to User Language]
    G2 --> H
    H --> I[TTS Audio Output]
    
    E1 --> M[(Memory DB)]
    F --> M
    G1 --> M
